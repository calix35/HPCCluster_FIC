# üéØ Proyecto: Ejemplos de Ejecuci√≥n en Cl√∫ster HPC FIC

Este repositorio contiene ejemplos de programas dise√±ados para ejecutarse en un cl√∫ster basado en **Microsoft HPC Pack**. Los ejemplos incluyen programas en **Python**, **C**, **C++**, **MPI** y **Java**, listos para ser lanzados usando diferentes tipos de trabajos (Single-Task, Parametric Sweep, MPI Jobs).

---

## üìë √çndice

- [üèõÔ∏è Arquitectura del Cl√∫ster](#Ô∏è-arquitectura-del-cl√∫ster)
- [‚öôÔ∏è Plataforma de Ejecuci√≥n](#Ô∏è-plataforma-de-ejecuci√≥n)
- [üìÇ Espacio compartido](#-espacio-compartido)
- [üß© Ejemplos disponibles](#-ejemplos-disponibles)
- [üì¢ Recomendaciones generales](#-recomendaciones-generales)
- [üöÄ C√≥mo empezar](#-c√≥mo-empezar)

---

## üèõÔ∏è Arquitectura del Cl√∫ster

El cl√∫ster est√° compuesto de **tres servidores** conectados mediante una red interna:

| Servidor         | Rol                                | Cores disponibles |
|------------------|------------------------------------|-------------------|
| **MasterServer1** | Head Node + Compute Node             | 32 cores          |
| **MasterServer2** | Compute Node                        | 32 cores          |
| **MasterServer3** | Compute Node (parcialmente virtualizado)       | 16 cores          |

Todos los servidores est√°n integrados con almacenamiento compartido a trav√©s de la carpeta `\\10.0.0.1\HPCShare\`.

---

## üßÆ Notas sobre Virtualizaci√≥n en el Cl√∫ster

El servidor **MasterServer3** ejecuta simult√°neamente servicios de virtualizaci√≥n utilizando **Hyper-V**, lo que explica que solo est√©n disponibles 16 de sus 32 n√∫cleos para el cl√∫ster HPC.

Actualmente, en este servidor se alojan **cuatro m√°quinas virtuales**, destinadas a brindar servicios auxiliares a nivel institucional y acad√©mico:

| M√°quina | Direcci√≥n IP         | Sistema Operativo     | Prop√≥sito                                | Nombre DNS             |
|---------|----------------------|------------------------|------------------------------------------|------------------------|
| VM1     | 148.237.28.38        | Windows Server 2022    | Servidor Web + Base de Datos             | `fic1.uat.edu.mx`      |
| VM2     | 148.237.28.34        | Windows Server 2022    | Servidor Web + Base de Datos             | `fic2.uat.edu.mx`      |
| VM3     | 148.237.28.36        | Ubuntu Server 22.04    | Contenedores Docker para proyectos web   | `fic3.uat.edu.mx`      |
| VM4     | 148.237.28.35        | Ubuntu Server 18.04    | Simulaci√≥n y desarrollo con ROS          | `fic4.uat.edu.mx`      |

> **Importante:** Todas las m√°quinas virtuales y el cl√∫ster solo son accesibles desde la **red interna de la Universidad Aut√≥noma de Tamaulipas**. No se permite el acceso desde redes externas.

Estas m√°quinas permiten el despliegue de aplicaciones web, backend de proyectos estudiantiles, y simulaciones con robots en entornos ROS. Este esquema de virtualizaci√≥n permite aprovechar el hardware del nodo sin comprometer la operaci√≥n principal del cl√∫ster, y fomenta la integraci√≥n de servicios cient√≠ficos, educativos y de desarrollo tecnol√≥gico sobre una misma infraestructura.
---

## üîê Acceso a las m√°quinas virtuales

Los usuarios que deseen utilizar alguna de las VMs deben **solicitar el acceso previamente**, indicando:

- Su **cuenta institucional** (`usuario@...uat.edu.mx`)
- El **objetivo acad√©mico o de desarrollo**
- En el caso de VM3, el **nombre del proyecto**

### 1. VM1 y VM2 ‚Äî Windows Server 2022 (`fic1`, `fic2`)

- **Acceso:** Escritorio Remoto (**RDP**)
- **Credenciales:** Cuenta institucional
- **Prop√≥sito:** Desarrollo web, pruebas de bases de datos
- **Uso:** Individual por usuario con configuraci√≥n propia
- **Responsabilidad:** El usuario instala y configura el entorno que necesite

### 2. VM4 ‚Äî Ubuntu 18.04 con ROS (`fic4`)

- **Acceso:** Escritorio Remoto (**RDP**) y tambi√©n **SSH**
- **Credenciales:** Cuenta institucional
- **Prop√≥sito:** Uso de ROS (Robot Operating System) para simulaciones
- **Uso:** **Compartido entre todos los usuarios autorizados**
- **Estado inicial:** ROS ya preinstalado; el resto de la configuraci√≥n debe realizarla cada usuario seg√∫n sus necesidades

### 3. VM3 ‚Äî Ubuntu 22.04 con Docker (`fic3`)

- **Acceso:** **SSH**
- **Credenciales:** Cuenta institucional
- **Prop√≥sito:** Despliegue de servicios web o backend con Docker
- **Uso:** Espacio aislado por proyecto; el usuario tiene **acceso como administrador** dentro de su entorno
- **Responsabilidad:** El usuario es completamente responsable de la configuraci√≥n, instalaci√≥n de contenedores y mantenimiento

---

En todos los casos, se espera que el usuario tenga la capacidad t√©cnica para instalar, configurar y mantener su entorno de trabajo. Se recomienda seguir buenas pr√°cticas de seguridad, respaldo y documentaci√≥n.

## ‚öôÔ∏è Plataforma de Ejecuci√≥n

Se utiliza **Microsoft HPC Pack** como software de gesti√≥n de trabajos y recursos del cl√∫ster.

Los usuarios tienen dos opciones para interactuar con el cl√∫ster:

- **Desde Windows**:
  1. Instalar **[HPC Pack Client Utilities (HpcClient_x86.msi o HpcClient_x64.msi)](https://www.microsoft.com/en-us/download/details.aspx?id=106334)** (versi√≥n compatible: HPC Pack 2019 Update 3).
  2. Conectar al Head Node (`masterserver1.uat.edu.mx`).

- **Desde navegador web**:
  - Acceder a: [https://masterserver1.uat.edu.mx](https://masterserver1.uat.edu.mx)
  - Iniciar sesi√≥n utilizando sus credenciales institucionales.

---

## üìÇ Espacio compartido

Cada usuario debe montar la unidad de red para acceder a su espacio de trabajo personal.

### üîπ Ruta UNC

```
\\masterserver1.uat.edu.mx\HPCShare\usuario
```
*(reemplazando `usuario` por su nombre de usuario institucional).*

---

### üîπ C√≥mo montar la carpeta manualmente en Windows

**Opci√≥n 1: Desde el Explorador de archivos**

1. Abrir **Explorador de archivos**.
2. Clic derecho en **Este equipo** > **Conectar a unidad de red...**.
3. Unidad: `Z:` (o la que prefieras).
4. Carpeta: `\\masterserver1.uat.edu.mx\HPCShare\usuario`
5. Activar:
   - ‚úÖ "Reconectar al iniciar sesi√≥n"
   - ‚úÖ "Conectar usando credenciales diferentes" (si no est√°s en el dominio)
6. Finalizar y colocar usuario y contrase√±a:
   - Usuario: `uat\usuario`
   - Contrase√±a: la de tu cuenta institucional.

**Opci√≥n 2: Desde l√≠nea de comandos (cmd.exe)**

```bat
net use Z: \\masterserver1.uat.edu.mx\HPCShare\usuario /persistent:yes
```

---

## üß© Ejemplos disponibles

| Carpeta                                                                 | Descripci√≥n                                      |
|-------------------------------------------------------------------------|--------------------------------------------------|
| [**Ejemplo_Entorno_Virtual_Python**](./Ejemplo_Entorno_Virtual_Python/README.md) | Creaci√≥n de entorno virtual de Python           |
| [**Ejemplo_Python_Simple**](./Ejemplo_Python_Simple/README.md)         | Ejecuci√≥n de m√∫ltiples simulaciones en paralelo |
| [**Ejemplo_Python_MPI**](./Ejemplo_Python_MPI/README.md)            | Ejecuci√≥n de simulaci√≥n distribuida con MPI en Python |
| [**Ejemplo_C_Lapack**](./Ejemplo_C_Lapack/README.md)              | Resoluci√≥n de sistemas lineales con LAPACK en C |
| [**Ejemplo_C_MPI**](./Ejemplo_C_MPI/README.md)                 | "Hola mundo" paralelo usando MPI en C           |
| [**Ejemplo_Java**](./Ejemplo_Java/README.md)                  | Simulaci√≥n aleatoria utilizando Java            |

Cada ejemplo incluye su propio `README.md` con instrucciones detalladas para su ejecuci√≥n.

---

## üì¢ Recomendaciones generales

- Verifica siempre que tu entorno de trabajo (entorno virtual, ejecutables compilados, etc.) est√© listo **antes** de enviar trabajos.
- Consulta en el portal web de HPC Pack el estado de los nodos y trabajos enviados.
- Evita usar todos los recursos disponibles si no es estrictamente necesario para permitir uso compartido del cl√∫ster.
- Usa rutas **UNC** completas en el "Working Directory" y no rutas locales (Para el mejor funcionamiento interno, usa la red privada 10.0.0.1 para el almacenamiento compartido, y la red masterserver1.uat.edu.mx solo desde tu computadora personal).
- Mant√©n tus carpetas organizadas dentro de `HPCShare`.

---

## üöÄ C√≥mo empezar

1. **Instala** HPC Client o accede v√≠a navegador.
2. **Con√©ctate** al Head Node.
3. **Monta** tu carpeta compartida.
4. **Explora** los ejemplos.
5. **Env√≠a** tu primer trabajo al cl√∫ster.

¬°Bienvenido al procesamiento de alto desempe√±o con HPC FIC!
