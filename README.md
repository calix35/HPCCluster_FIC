# üéØ Proyecto: Ejemplos de Ejecuci√≥n en Cl√∫ster HPC FIC

Este repositorio contiene ejemplos de programas dise√±ados para ejecutarse en un cl√∫ster basado en **Microsoft HPC Pack**. Los ejemplos incluyen programas en **Python**, **C**, **C++**, **MPI** y **Java**, listos para ser lanzados usando diferentes tipos de trabajos (Single-Task, Parametric Sweep, MPI Jobs).

---

## üìë √çndice

- [üèõÔ∏è Arquitectura del Cl√∫ster](#Ô∏è-arquitectura-del-cl√∫ster)
- [‚öôÔ∏è Plataforma de Ejecuci√≥n](#Ô∏è-plataforma-de-ejecuci√≥n)
- [üìÇ Espacio compartido](#-espacio-compartido)
- [üß© Ejemplos disponibles](#-ejemplos-disponibles)
- [üì¢ Recomendaciones generales](#-recomendaciones-generales)
- [üöÄ C√≥mo empezar](#-c√≥mo-empezar)

---

## üèõÔ∏è Arquitectura del Cl√∫ster

El cl√∫ster est√° compuesto de **tres servidores** conectados mediante una red interna:

| Servidor         | Rol                                | Cores disponibles |
|------------------|------------------------------------|-------------------|
| **MasterServer1** | Head Node + Compute Node             | 32 cores          |
| **MasterServer2** | Compute Node                        | 32 cores          |
| **MasterServer3** | Compute Node (parcialmente virtualizado)       | 16 cores          |

Todos los servidores est√°n integrados con almacenamiento compartido a trav√©s de la carpeta `\\10.0.0.1\HPCShare\`.

---

## üßÆ Notas sobre Virtualizaci√≥n en el Cl√∫ster

El servidor **MasterServer3** ejecuta simult√°neamente servicios de virtualizaci√≥n utilizando **Hyper-V**, lo que explica que solo est√©n disponibles 16 de sus 32 n√∫cleos para el cl√∫ster HPC.

Actualmente, en este servidor se alojan **cuatro m√°quinas virtuales**, destinadas a brindar servicios auxiliares a nivel institucional y acad√©mico:

- **VM1:** Windows Server 2022 ‚Äî Servidor Web + Base de Datos
- **VM2:** Windows Server 2022 ‚Äî Servidor Web + Base de Datos
- **VM3:** Ubuntu Server 22.04 ‚Äî Servidor Web con m√∫ltiples contenedores Docker
- **VM4:** Ubuntu Server 18.04 ‚Äî Servidor especializado con ROS (Robot Operating System)

Estas m√°quinas permiten el despliegue de aplicaciones web, backend de proyectos estudiantiles, y simulaciones con robots en entornos ROS.

Este esquema de virtualizaci√≥n permite aprovechar el hardware del nodo sin comprometer la operaci√≥n principal del cl√∫ster, y fomenta la integraci√≥n de servicios cient√≠ficos, educativos y de desarrollo tecnol√≥gico sobre una misma infraestructura.
---

## ‚öôÔ∏è Plataforma de Ejecuci√≥n

Se utiliza **Microsoft HPC Pack** como software de gesti√≥n de trabajos y recursos del cl√∫ster.

Los usuarios tienen dos opciones para interactuar con el cl√∫ster:

- **Desde Windows**:
  1. Instalar **[HPC Pack Client Utilities (HpcClient_x86.msi o HpcClient_x64.msi)](https://www.microsoft.com/en-us/download/details.aspx?id=106334)** (versi√≥n compatible: HPC Pack 2019 Update 3).
  2. Conectar al Head Node (`masterserver1.uat.edu.mx`).

- **Desde navegador web**:
  - Acceder a: [https://masterserver1.uat.edu.mx](https://masterserver1.uat.edu.mx)
  - Iniciar sesi√≥n utilizando sus credenciales institucionales.

---

## üìÇ Espacio compartido

Cada usuario debe montar la unidad de red para acceder a su espacio de trabajo personal.

### üîπ Ruta UNC

```
\\masterserver1.uat.edu.mx\HPCShare\usuario
```
*(reemplazando `usuario` por su nombre de usuario institucional).*

---

### üîπ C√≥mo montar la carpeta manualmente en Windows

**Opci√≥n 1: Desde el Explorador de archivos**

1. Abrir **Explorador de archivos**.
2. Clic derecho en **Este equipo** > **Conectar a unidad de red...**.
3. Unidad: `Z:` (o la que prefieras).
4. Carpeta: `\\masterserver1.uat.edu.mx\HPCShare\usuario`
5. Activar:
   - ‚úÖ "Reconectar al iniciar sesi√≥n"
   - ‚úÖ "Conectar usando credenciales diferentes" (si no est√°s en el dominio)
6. Finalizar y colocar usuario y contrase√±a:
   - Usuario: `uat\usuario`
   - Contrase√±a: la de tu cuenta institucional.

**Opci√≥n 2: Desde l√≠nea de comandos (cmd.exe)**

```bat
net use Z: \\masterserver1.uat.edu.mx\HPCShare\usuario /persistent:yes
```

---

## üß© Ejemplos disponibles

| Carpeta                                                                 | Descripci√≥n                                      |
|-------------------------------------------------------------------------|--------------------------------------------------|
| [**Ejemplo_Entorno_Virtual_Python**](./Ejemplo_Entorno_Virtual_Python/README.md) | Creaci√≥n de entorno virtual de Python           |
| [**Ejemplo_Python_Simple**](./Ejemplo_Python_Simple/README.md)         | Ejecuci√≥n de m√∫ltiples simulaciones en paralelo |
| [**Ejemplo_Python_MPI**](./Ejemplo_Python_MPI/README.md)            | Ejecuci√≥n de simulaci√≥n distribuida con MPI en Python |
| [**Ejemplo_C_Lapack**](./Ejemplo_C_Lapack/README.md)              | Resoluci√≥n de sistemas lineales con LAPACK en C |
| [**Ejemplo_C_MPI**](./Ejemplo_C_MPI/README.md)                 | "Hola mundo" paralelo usando MPI en C           |
| [**Ejemplo_Java**](./Ejemplo_Java/README.md)                  | Simulaci√≥n aleatoria utilizando Java            |

Cada ejemplo incluye su propio `README.md` con instrucciones detalladas para su ejecuci√≥n.

---

## üì¢ Recomendaciones generales

- Verifica siempre que tu entorno de trabajo (entorno virtual, ejecutables compilados, etc.) est√© listo **antes** de enviar trabajos.
- Consulta en el portal web de HPC Pack el estado de los nodos y trabajos enviados.
- Evita usar todos los recursos disponibles si no es estrictamente necesario para permitir uso compartido del cl√∫ster.
- Usa rutas **UNC** completas en el "Working Directory" y no rutas locales (Para el mejor funcionamiento interno, usa la red privada 10.0.0.1 para el almacenamiento compartido, y la red masterserver1.uat.edu.mx solo desde tu computadora personal).
- Mant√©n tus carpetas organizadas dentro de `HPCShare`.

---

## üöÄ C√≥mo empezar

1. **Instala** HPC Client o accede v√≠a navegador.
2. **Con√©ctate** al Head Node.
3. **Monta** tu carpeta compartida.
4. **Explora** los ejemplos.
5. **Env√≠a** tu primer trabajo al cl√∫ster.

¬°Bienvenido al procesamiento de alto desempe√±o con HPC FIC!
